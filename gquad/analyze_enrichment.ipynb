{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as ticker\n",
    "import re\n",
    "from scipy.stats import ks_2samp, ttest_ind, ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sist_melt(fn):\n",
    "    \"\"\"Parse raw SIST melt output; return an array of probabilities\"\"\"\n",
    "    data = []\n",
    "    with open(fn, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if 'Position' in line or 'WARNING' in line:\n",
    "                continue\n",
    "            line = line.split()\n",
    "            line[0], line[1], line[2], line[3] = int(line[0])-1, float(line[1]), float(line[2]), float(line[3])\n",
    "            data.append(line[1])\n",
    "    return np.array(data)\n",
    "\n",
    "def parse_sist_Z(fn):\n",
    "    \"\"\"Parse raw SIST melt output; return an array of probabilities\"\"\"\n",
    "    data = []\n",
    "    with open(fn, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if 'Position' in line or 'WARNING' in line:\n",
    "                continue\n",
    "            line = line.split()\n",
    "            line[0], line[1], line[2], line[3] = int(line[0])-1, float(line[1]), float(line[2]), float(line[3])\n",
    "            data.append(line[2])\n",
    "    return np.array(data)\n",
    "\n",
    "def parse_sist_cruciform(fn):\n",
    "    \"\"\"Parse raw SIST melt output; return an array of probabilities\"\"\"\n",
    "    data = []\n",
    "    with open(fn, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if 'Position' in line or 'WARNING' in line:\n",
    "                continue\n",
    "            line = line.split()\n",
    "            line[0], line[1], line[2], line[3] = int(line[0])-1, float(line[1]), float(line[2]), float(line[3])\n",
    "            data.append(line[3])\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrichment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "centromere = '2'\n",
    "long_name = ''\n",
    "cen_len = {'2': 24561, '3': 103827, '4': 93914, 'X': 70181, 'Y': 139957}\n",
    "master_dict = {}\n",
    "cen_master_dict = {}\n",
    "\n",
    "for n in os.listdir(\"control/dna/C{}\".format(centromere)):\n",
    "    contig = '_'.join(n.split('-')[2].split('_')[:-1])\n",
    "    start = int(n.split('-')[2].split('_')[-1])\n",
    "    end =  int(n.split('-')[3])\n",
    "    \n",
    "    contig_identifier = '-'.join([contig, str(start)])\n",
    "\n",
    "    fns = glob.glob('R_gquad_results/*/*{}.csv'.format(contig))\n",
    "    for fn in fns:\n",
    "        if contig_identifier not in master_dict:\n",
    "            master_dict[contig_identifier] = np.zeros((cen_len[centromere],))\n",
    "        \n",
    "            \n",
    "        arr = master_dict[contig_identifier].copy()\n",
    "\n",
    "        df = pd.read_csv(fn)\n",
    "        if len(df[df['sequence_position'] == '-']) >= 1:\n",
    "            continue\n",
    "        df = df[df['sequence_position'] >= start ]\n",
    "        df = df[df['sequence_position'] <= end ]\n",
    "\n",
    "        try:\n",
    "\n",
    "            for s_pos, s_len, s_lik in zip(df['sequence_position'], df['sequence_length'], df['likeliness']):\n",
    "                if s_lik == '*':\n",
    "                    num = 1\n",
    "                elif s_lik == '**':\n",
    "                    num = 2\n",
    "                elif s_lik == '***':\n",
    "                    num = 3\n",
    "                \n",
    "                s_start = s_pos - start\n",
    "                arr[int(s_start): (int(s_start) + int(s_len) + 1)] += num\n",
    "                \n",
    "        except:\n",
    "\n",
    "            for s_pos, s_len in zip(df['sequence_position'], df['sequence_length']):\n",
    "                num = 2\n",
    "                \n",
    "                s_start = s_pos - start\n",
    "                arr[int(s_start): (int(s_start) + int(s_len) + 1)] += num\n",
    "        \n",
    "        master_dict[contig_identifier] = arr.copy()\n",
    "\n",
    "\n",
    "# For the centromere\n",
    "for n in [n.replace('\\uf03a', ':') for n in os.listdir('cen/dna/C{}'.format(centromere))]:\n",
    "    if '.fai' in n:\n",
    "        continue\n",
    "    contig = n.split('-')[1]\n",
    "    \n",
    "    contig_identifier = contig\n",
    "\n",
    "    fns = glob.glob('R_gquad_results/*/*{}.csv'.format(contig))\n",
    "    for fn in fns:\n",
    "        if contig_identifier not in cen_master_dict:\n",
    "            cen_master_dict[contig_identifier] = np.zeros((cen_len[centromere],))\n",
    "        else:\n",
    "            arr = cen_master_dict[contig_identifier].copy()\n",
    "\n",
    "        \n",
    "        df = pd.read_csv(fn)\n",
    "        if len(df[df['sequence_position'] == '-']) >= 1:\n",
    "            continue\n",
    "        try:\n",
    "            \n",
    "            for s_pos, s_len, s_lik in zip(df['sequence_position'], df['sequence_length'], df['likeliness']):\n",
    "                if s_lik == '*':\n",
    "                    num = 1\n",
    "                elif s_lik == '**':\n",
    "                    num = 2\n",
    "                elif s_lik == '***':\n",
    "                    num = 3\n",
    "                \n",
    "                s_start = s_pos\n",
    "                arr[int(s_start): (int(s_start) + int(s_len) + 1)] += num\n",
    "                \n",
    "        except:\n",
    "            for s_pos, s_len in zip(df['sequence_position'], df['sequence_length']):\n",
    "                num = 2\n",
    "                \n",
    "                s_start = s_pos\n",
    "                arr[int(s_start): (int(s_start) + int(s_len) + 1)] += num\n",
    "        \n",
    "        cen_master_dict[contig_identifier] = arr.copy()\n",
    "\n",
    "\n",
    "all_ks_avgs = []\n",
    "cen_iden = list(cen_master_dict.keys())[0]\n",
    "\n",
    "for key, values in master_dict.items():\n",
    "    all_ks_avgs.append(ks_2samp(cen_master_dict[cen_iden], values)[1])\n",
    "print('Average P Value for centromere', centromere, \":\", np.mean(np.array(all_ks_avgs)))\n",
    "\n",
    "\n",
    "hue = []\n",
    "data = []\n",
    "names = []\n",
    "t_cen = []\n",
    "t_con = []\n",
    "minl = 0\n",
    "\n",
    "sdata = np.mean(cen_master_dict[cen_iden])\n",
    "t_cen.append(sdata)\n",
    "data.append(sdata)\n",
    "hue.append(1)\n",
    "names.append('Cen')\n",
    "np.savetxt(\"\".join([\"control/csv-results/long-centromere-\", centromere, \"-gquad\" + long_name + \".csv\"]), data, delimiter=\",\")\n",
    "\n",
    "data = []\n",
    "names = []\n",
    "\n",
    "for key, values in master_dict.items():\n",
    "    sdata = np.mean(values)\n",
    "    t_con.append(sdata)\n",
    "    data.append(sdata)\n",
    "    hue.append(0)\n",
    "    names.append('Control')\n",
    "np.savetxt(\"\".join([\"control/csv-results/long-control-\", centromere, \"-gquad\" + long_name + \".csv\"]), data, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking Contigs based on GQuad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "# This creates a dictionary of all lengths of all contigs\n",
    "sequence_lengths = {}\n",
    "for seq_record in SeqIO.parse('dm6.fasta', \"fasta\"):\n",
    "    sequence_lengths[seq_record.id] = len(seq_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dict_contig = {}\n",
    "\n",
    "for n in sequence_lengths.keys():\n",
    "    fns = glob.glob('R_gquad_results/*/*{}.csv'.format(n))\n",
    "    for fn in fns:\n",
    "        if n not in master_dict_contig:\n",
    "            master_dict_contig[n] = np.zeros((sequence_lengths[n],))\n",
    "        \n",
    "            \n",
    "        arr = master_dict_contig[n].copy()\n",
    "\n",
    "        df = pd.read_csv(fn)\n",
    "        if len(df[df['sequence_position'] == '-']) >= 1:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "\n",
    "            for s_pos, s_len, s_lik in zip(df['sequence_position'], df['sequence_length'], df['likeliness']):\n",
    "                if s_lik == '*':\n",
    "                    num = 1\n",
    "                elif s_lik == '**':\n",
    "                    num = 2\n",
    "                elif s_lik == '***':\n",
    "                    num = 3\n",
    "                \n",
    "                s_start = s_pos \n",
    "                arr[int(s_start): (int(s_start) + int(s_len) + 1)] += num\n",
    "                \n",
    "        except:\n",
    "\n",
    "            for s_pos, s_len in zip(df['sequence_position'], df['sequence_length']):\n",
    "                num = 2\n",
    "                \n",
    "                s_start = s_pos\n",
    "                arr[int(s_start): (int(s_start) + int(s_len) + 1)] += num\n",
    "        \n",
    "        master_dict_contig[n] = arr.copy()\n",
    "    \n",
    "for key, values in master_dict_contig.items():\n",
    "    master_dict_contig[key] = values.mean()\n",
    "\n",
    "master_list_contig = []\n",
    "for key, value in master_dict_contig.items():\n",
    "    master_list_contig.append([key, value])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "  \n",
    "master_list_contig.sort(key = lambda x: x[1], reverse=True)\n",
    "\n",
    "# field names \n",
    "fields = ['Name', 'Average Likelihood'] \n",
    "    \n",
    "# data rows of csv file \n",
    "rows = master_list_contig\n",
    "  \n",
    "with open('rank_non_b_with_gquad.csv', 'w') as f:\n",
    "      \n",
    "    # using csv.writer method from CSV package\n",
    "    write = csv.writer(f)\n",
    "      \n",
    "    write.writerow(fields)\n",
    "    write.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GQuad pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cen = None\n",
    "total_control = None\n",
    "\n",
    "cens_l = []\n",
    "controls_l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centromere = 'Y'\n",
    "long_name = ''\n",
    "cen_len = {'2': 24561, '3': 103827, '4': 93914, 'X': 70181, 'Y': 139957}\n",
    "master_dict = {}\n",
    "cen_master_dict = {}\n",
    "non_b = 'str'\n",
    "\n",
    "for n in os.listdir(\"control/dna/C{}\".format(centromere)):\n",
    "    contig = '_'.join(n.split('-')[2].split('_')[:-1])\n",
    "    start = int(n.split('-')[2].split('_')[-1])\n",
    "    end =  int(n.split('-')[3])\n",
    "    \n",
    "    contig_identifier = '-'.join([contig, str(start)])\n",
    "\n",
    "    control_dna_dict = {\n",
    "        'aphased': 0,\n",
    "        'gquad': 0,\n",
    "        'hdna': 0,\n",
    "        'slipped': 0,\n",
    "        'str': 0,\n",
    "        'tfo': 0,\n",
    "        'zdna': 0\n",
    "    }\n",
    "\n",
    "    cen_dna_dict = {\n",
    "        'aphased': 0,\n",
    "        'gquad': 0,\n",
    "        'hdna': 0,\n",
    "        'slipped': 0,\n",
    "        'str': 0,\n",
    "        'tfo': 0,\n",
    "        'zdna': 0\n",
    "    }\n",
    "\n",
    "    fns = glob.glob('R_gquad_results/{}/*{}.csv'.format(non_b, contig))\n",
    "    for fn in fns:\n",
    "\n",
    "        if contig_identifier not in master_dict:\n",
    "            master_dict[contig_identifier] = np.zeros((cen_len[centromere],))\n",
    "        \n",
    "            \n",
    "        arr = master_dict[contig_identifier].copy()\n",
    "\n",
    "        key=None\n",
    "\n",
    "        if 'aphased_' in fn:\n",
    "            key = 'aphased'\n",
    "        if 'gquad_' in fn:\n",
    "            key = 'gquad'\n",
    "        if 'hdna_' in fn:\n",
    "            key = 'hdna'\n",
    "        if 'slipped_' in fn:\n",
    "            key = 'slipped'\n",
    "        if 'str_' in fn:\n",
    "            key = 'str'\n",
    "        if 'tfo_' in fn:\n",
    "            key = 'tfo'\n",
    "        if 'zdna_' in fn:\n",
    "            key = 'zdna'\n",
    "\n",
    "        df = pd.read_csv(fn)\n",
    "        if len(df[df['sequence_position'] == '-']) >= 1:\n",
    "            continue\n",
    "        df = df[df['sequence_position'] >= start ]\n",
    "        df = df[df['sequence_position'] <= end ]\n",
    "\n",
    "        try:\n",
    "\n",
    "            for s_pos, s_len, s_lik in zip(df['sequence_position'], df['sequence_length'], df['likeliness']):\n",
    "                num = 1\n",
    "                s_start = s_pos - start\n",
    "                arr[int(s_start): (int(s_start) + int(s_len) + 1)] += num\n",
    "                number_of_stars = ( num * int(s_len) )\n",
    "                control_dna_dict[key] += number_of_stars\n",
    "                \n",
    "        except:\n",
    "\n",
    "            for s_pos, s_len in zip(df['sequence_position'], df['sequence_length']):\n",
    "                num = 1\n",
    "                s_start = s_pos - start\n",
    "                arr[int(s_start): (int(s_start) + int(s_len) + 1)] += num\n",
    "                number_of_stars = ( num * int(s_len) )\n",
    "                control_dna_dict[key] += number_of_stars\n",
    "        \n",
    "        master_dict[contig_identifier] = arr.copy()\n",
    "\n",
    "\n",
    "# For the centromere\n",
    "for n in [n.replace('\\uf03a', ':') for n in os.listdir('cen/dna/C{}'.format(centromere))]:\n",
    "    if '.fai' in n:\n",
    "        continue\n",
    "    contig = n.split('-')[1]\n",
    "    \n",
    "    contig_identifier = contig\n",
    "\n",
    "    fns = glob.glob('R_gquad_results/{}/*{}.csv'.format(non_b, contig))\n",
    "    for fn in fns:\n",
    "        if contig_identifier not in cen_master_dict:\n",
    "            cen_master_dict[contig_identifier] = np.zeros((cen_len[centromere],))\n",
    "        else:\n",
    "            arr = cen_master_dict[contig_identifier].copy()\n",
    "        \n",
    "        if 'aphased_' in fn:\n",
    "            key = 'aphased'\n",
    "        if 'gquad_' in fn:\n",
    "            key = 'gquad'\n",
    "        if 'hdna_' in fn:\n",
    "            key = 'hdna'\n",
    "        if 'slipped_' in fn:\n",
    "            key = 'slipped'\n",
    "        if 'str_' in fn:\n",
    "            key = 'str'\n",
    "        if 'tfo_' in fn:\n",
    "            key = 'tfo'\n",
    "        if 'zdna_' in fn:\n",
    "            key = 'zdna'\n",
    "\n",
    "        \n",
    "        df = pd.read_csv(fn)\n",
    "        if len(df[df['sequence_position'] == '-']) >= 1:\n",
    "            continue\n",
    "        try:\n",
    "            \n",
    "            for s_pos, s_len, s_lik in zip(df['sequence_position'], df['sequence_length'], df['likeliness']):\n",
    "                num = 1\n",
    "                s_start = s_pos\n",
    "                arr[int(s_start): (int(s_start) + int(s_len) + 1)] += num\n",
    "                number_of_stars = ( num * int(s_len) )\n",
    "                cen_dna_dict[key] += number_of_stars\n",
    "                \n",
    "        except:\n",
    "            for s_pos, s_len in zip(df['sequence_position'], df['sequence_length']):\n",
    "                num = 1\n",
    "                s_start = s_pos\n",
    "                arr[int(s_start): (int(s_start) + int(s_len) + 1)] += num\n",
    "                number_of_stars = ( num * int(s_len) )\n",
    "                cen_dna_dict[key] += number_of_stars\n",
    "        \n",
    "        cen_master_dict[contig_identifier] = arr.copy()\n",
    "\n",
    "\n",
    "all_ks_avgs = []\n",
    "temp_controls_l = []\n",
    "cen_iden = list(cen_master_dict.keys())[0]\n",
    "cens_l.append(np.mean(cen_master_dict[cen_iden]))\n",
    "counter = 1\n",
    "for key, values in master_dict.items():\n",
    "    temp_controls_l.append(np.mean(values))\n",
    "    all_ks_avgs.append(ks_2samp(cen_master_dict[cen_iden], values)[1])\n",
    "    if counter >= 50:\n",
    "        controls_l.append(temp_controls_l)\n",
    "        break \n",
    "    counter += 1\n",
    "\n",
    "\n",
    "hue = []\n",
    "data = []\n",
    "names = []\n",
    "t_cen = []\n",
    "t_con = []\n",
    "minl = 0\n",
    "\n",
    "sdata = np.mean(cen_master_dict[cen_iden])\n",
    "t_cen.append(sdata)\n",
    "data.append(sdata)\n",
    "hue.append(1)\n",
    "names.append('Cen')\n",
    "\n",
    "data = []\n",
    "names = []\n",
    "\n",
    "for key, values in master_dict.items():\n",
    "    sdata = np.mean(values)\n",
    "    t_con.append(sdata)\n",
    "    data.append(sdata)\n",
    "    hue.append(0)\n",
    "    names.append('Control')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_1samp(np.mean(\n",
    "    np.array(controls_l),\n",
    "    axis=0,\n",
    ").tolist(), np.mean(cens_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if total_cen == None:\n",
    "    total_cen = cen_dna_dict\n",
    "else:\n",
    "    for key, value in cen_dna_dict.items():\n",
    "        total_cen[key] += value\n",
    "\n",
    "if total_control == None:\n",
    "    total_control = control_dna_dict\n",
    "else:\n",
    "    for key, value in control_dna_dict.items():\n",
    "        total_control[key] += value\n",
    "\n",
    "print('Cen', total_cen)\n",
    "print('Control', total_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the outputs from above into the dictionary below and run the next cell for the percents.\n",
    "# Replace the 0s with the outputs from above\n",
    "\n",
    "# The Regular Method Totals\n",
    "total_cen_1 = {'aphased': 0, 'gquad': 0, 'hdna': 0, 'slipped': 0, 'str': 0, 'tfo': 0, 'zdna': 0}\n",
    "total_control_1 ={'aphased': 0, 'gquad': 0, 'hdna': 0, 'slipped': 0, 'str': 0, 'tfo': 0, 'zdna': 0}\n",
    "\n",
    "# Different method where we addonly 1 and not the total likelihood\n",
    "total_cen_2 = {'aphased': 0, 'gquad': 0, 'hdna': 0, 'slipped': 0, 'str': 0, 'tfo': 0, 'zdna': 0}\n",
    "total_control_2 = {'aphased': 0, 'gquad': 0, 'hdna': 0, 'slipped': 0, 'str': 0, 'tfo': 0, 'zdna': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "dict_of_int = total_control_2\n",
    "for key, value in dict_of_int.items():\n",
    "    total += value\n",
    "\n",
    "for key, value in dict_of_int.items():\n",
    "    dict_of_int[key] = value/total\n",
    "\n",
    "dict_of_int"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9fb27f246a974b07d903088cb2226249d01ae4c707c3503890a928204029e034"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

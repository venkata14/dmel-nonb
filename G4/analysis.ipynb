{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "# # This creates a dictionary of all lengths of all contigs\n",
    "sequence_lengths = {}\n",
    "for seq_record in SeqIO.parse('ref/dm6.fasta', \"fasta\"):\n",
    "    sequence_lengths[seq_record.id] = len(seq_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking contigs based on G4Hunter scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theses set of loops create a dictionary where the key is a contig and the value us an array of 0 and 1s where there a G4 exists in that area.\n",
    "\n",
    "threshold = 1\n",
    "master_dict_contig = {}\n",
    "for n in sequence_lengths.keys():\n",
    "    fns = glob.glob('results/Results_dm6_threshold_{}/{}.split.txt'.format(threshold, n))\n",
    "    for fn in fns:\n",
    "        if n not in master_dict_contig:\n",
    "            master_dict_contig[n] = np.zeros((sequence_lengths[n],))\n",
    "        \n",
    "            \n",
    "        arr = master_dict_contig[n].copy()\n",
    "\n",
    "        df = pd.read_csv(fn, delimiter='\\t')\n",
    "\n",
    "        for r in df.iloc:\n",
    "            start = r['Start']\n",
    "            end = r['End']\n",
    "            arr[start: (end + 1)] += 1\n",
    "\n",
    "        master_dict_contig[n] = arr.copy()\n",
    "\n",
    "# Get the mean for each contig and replace the array\n",
    "for key, values in master_dict_contig.items():\n",
    "    master_dict_contig[key] = values.mean()\n",
    "\n",
    "# convert to list\n",
    "master_list_contig = []\n",
    "for key, value in master_dict_contig.items():\n",
    "    master_list_contig.append([key, value])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Sort the averages\n",
    "master_list_contig.sort(key = lambda x: x[1], reverse=True)\n",
    "\n",
    "# field names \n",
    "fields = ['Name', 'Density of G4s per Contig'] \n",
    "    \n",
    "# data rows of csv file \n",
    "rows = master_list_contig\n",
    "  \n",
    "with open('rank_contigs_with_G4Hunter_threshold_{}.csv'.format(threshold), 'w') as f:\n",
    "      \n",
    "    # using csv.writer method from CSV package\n",
    "    write = csv.writer(f)\n",
    "      \n",
    "    write.writerow(fields)\n",
    "    write.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining enrichement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the centromere to analyze the different centromeres\n",
    "centromere = 'Y'\n",
    "cen_len = {'2': 155000, '3': 103827, '4': 109000, 'X': 158600, 'Y': 139957}\n",
    "master_dict = {}\n",
    "cen_master_dict = {}\n",
    "threshold = 2\n",
    "\n",
    "# For controls\n",
    "for n in os.listdir(\"control/long_dna/C{}\".format(centromere)):\n",
    "    contig = '_'.join(n.split('-')[2].split('_')[:-1])\n",
    "    start = int(n.split('-')[2].split('_')[-1])\n",
    "    end =  int(n.split('-')[3])\n",
    "    \n",
    "    contig_identifier = '-'.join([contig, str(start)])\n",
    "\n",
    "    # The G4 file to open for each control contig\n",
    "    fn = 'results/Results_dm6_threshold_{}/{}.split.txt'.format(threshold, contig)\n",
    "\n",
    "    if contig_identifier not in master_dict:\n",
    "        master_dict[contig_identifier] = np.zeros((cen_len[centromere],))\n",
    "    \n",
    "    # For contigs where G4Hunter found no G4s\n",
    "    if not os.path.isfile(fn):\n",
    "        continue\n",
    "        \n",
    "    arr = master_dict[contig_identifier].copy()\n",
    "\n",
    "    df = pd.read_csv(fn, delimiter='\\t')\n",
    "    df['Score'] = abs(df['Score'])\n",
    "    df = df[df['Start'] >= start ]\n",
    "    df = df[df['End'] <= end ]\n",
    "\n",
    "    for r in df.iloc:\n",
    "        inner_start = r['Start'] - start\n",
    "        inner_end = r['End'] - end\n",
    "        arr[inner_start: (inner_end + 1)] += 1\n",
    "    \n",
    "    master_dict[contig_identifier] = arr.copy()\n",
    "\n",
    "\n",
    "#For the centromere\n",
    "for n in [n.replace('\\uf03a', ':') for n in os.listdir('cen/dna/C{}'.format(centromere))]:\n",
    "    if '.fai' in n:\n",
    "        continue\n",
    "    contig = n.split('-')[1]\n",
    "    \n",
    "    contig_identifier = contig\n",
    "\n",
    "    # The G4 file to open for each control contig\n",
    "    fn = 'results/Results_dm6_threshold_{}/{}.split.txt'.format(threshold, contig)\n",
    "    \n",
    "    if contig_identifier not in cen_master_dict:\n",
    "        cen_master_dict[contig_identifier] = np.zeros((cen_len[centromere],))\n",
    "    \n",
    "    arr = cen_master_dict[contig_identifier].copy()\n",
    "\n",
    "    \n",
    "    df = pd.read_csv(fn, delimiter='\\t')\n",
    "    df['Score'] = abs(df['Score'])\n",
    "    for r in df.iloc:\n",
    "        inner_start = r['Start']\n",
    "        inner_end = r['End']\n",
    "        arr[inner_start: (inner_end + 1)] += 1\n",
    "    \n",
    "    cen_master_dict[contig_identifier] = arr.copy()\n",
    "\n",
    "\n",
    "all_ks_avgs = []\n",
    "cen_iden = list(cen_master_dict.keys())[0]\n",
    "\n",
    "for key, values in master_dict.items():\n",
    "    all_ks_avgs.append(ks_2samp(cen_master_dict[cen_iden], values)[1])\n",
    "print('Average P Value for centromere', centromere, \":\", np.mean(np.array(all_ks_avgs)))\n",
    "\n",
    "\n",
    "hue = []\n",
    "data = []\n",
    "names = []\n",
    "t_cen = []\n",
    "t_con = []\n",
    "minl = 0\n",
    "\n",
    "sdata = np.mean(cen_master_dict[cen_iden])\n",
    "t_cen.append(sdata)\n",
    "data.append(sdata)\n",
    "hue.append(1)\n",
    "names.append('Cen')\n",
    "np.savetxt(\"\".join([\"control/csv-results/centromere-\", centromere, \"-G4Hunter-threshold-\" + str(threshold) + \"-.csv\"]), data, delimiter=\",\")\n",
    "\n",
    "data = []\n",
    "names = []\n",
    "\n",
    "for key, values in master_dict.items():\n",
    "    sdata = np.mean(values)\n",
    "    t_con.append(sdata)\n",
    "    data.append(sdata)\n",
    "    hue.append(0)\n",
    "    names.append('Control')\n",
    "np.savetxt(\"\".join([\"control/csv-results/long-control-\", centromere, \"-G4Hunter-threshold-\" + str(threshold) + \"-long-.csv\"]), data, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One sample T test\n",
    "from scipy.stats import ttest_1samp\n",
    "import pandas as pd\n",
    "cen_len_index = 'Y'\n",
    "threshold = 1\n",
    "\n",
    "ttest_1samp(\n",
    "    pd.read_csv(\"\".join([\"control/csv-results/long-control-\", cen_len_index, \"-G4Hunter-threshold-\" + str(threshold) + \"-long-.csv\"]), header=None).values,\n",
    "    float(pd.read_csv(\"\".join([\"control/csv-results/long-centromere-\", cen_len_index, \"-G4Hunter-threshold-\" + str(threshold) + \"-long-.csv\"]), header=None).values)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9fb27f246a974b07d903088cb2226249d01ae4c707c3503890a928204029e034"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
